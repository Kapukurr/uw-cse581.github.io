---
layout: page
title: Class Project
description: >-
    Class project information.
---

# Research project and preliminary paper
{:.no_toc}

## Table of contents
{: .no_toc .text-delta }

1. TOC
{:toc}




## Project description

As part of this class, you will be required to produce a preliminary research paper on the topic of computer ethics. These research projects will be conducted in groups of 2 students and can be in your general area of interest or in one of the areas that we are covering in class. You will be required to discuss your project idea with the class, and make adjustments as necessary. Your project can address various topics in computer ethics, and be focused on various disciplines within CS and related fields, but it should fall into one or more of the following categories (these are action possibilities listed in the book Data Feminism by D'Ignazio and Klein): 

* **Collect**: Compiling counter data (to add to existing data that may have "holes")
* **Analyze**: Demonstrate inequitable outcomes across groups 
* **Imagine**: Imagine the end-point not as “fairness”, but as co-liberation
* **Teach**: How might we engage and empower newcomers to the field of computer ethics, including practitioners and researchers?

My expectation for this research project is that it significantly extends previous findings in an area within CS. Your research project should be a plausible attempt at contributing a novel result. 
The final write-up should have the quality of a publishable paper, with the contribution being roughly that of a short paper (e.g., a workshop paper). The papers should be 4-6 pages long. This might sound short, but it’s much more difficult to write a concise and coherent story than it is to have unlimited space. Try to make one argument per sentence, and use one paragraph to zoom in on one argument. Use a template, i.e., find a paper that you particularly like and use it as a guideline on how to structure and write your own.  

## Examples to inspire your own research project 

### Collect: Compiling counter data

* https://feminicidiosmx.crowdmap.com/

* Jo, E. S., & Gebru, T. (2020, January). Lessons from archives: strategies for collecting sociocultural data in machine learning. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency (pp. 306-316).
* Marda, V., & Narayan, S. (2020, January). Data in New Delhi's predictive policing system. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency (pp. 317-324).
* Schlesinger, A., Edwards, W. K., & Grinter, R. E. (2017, May). Intersectional HCI: Engaging identity through gender, race, and class. In Proceedings of the 2017 CHI conference on human factors in computing systems (pp. 5412-5427).

### Analyze: Demonstrate societal impacts, such as inequitable outcomes across groups	

* How to use Value Sensitive Design/Envisioning cards: Friedman, B., & Hendry, D. (2012, May). The envisioning cards: a toolkit for catalyzing humanistic and technical imaginations. In Proceedings of the SIGCHI conference on human factors in computing systems (pp. 1145-1148).
* More on Value Sensitive Design: Friedman, B., & Hendry, D. G. (2019). Value sensitive design: Shaping technology with moral imagination. Mit Press. 
* Design Fiction: Noortman, Renee, Britta F. Schulte, Paul Marshall, Saskia Bakker, and Anna L. Cox. "HawkEye-Deploying a Design Fiction Probe." In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems, pp. 1-14. 2019.
* VSD and Design Fiction: Ballard, Stephanie, Karen M. Chappell, and Kristen Kennedy. "Judgment call the game: Using value sensitive design and design fiction to surface ethical concerns related to technology." In Proceedings of the 2019 on Designing Interactive Systems Conference, pp. 421-433. 2019.
* A Value Sensitive Design analysis to evaluate StackOverflow’s design and its  guidelines: Nigini Oliveira, Michael Muller, Nazareno Andrade, and Katharina Reinecke, "The Exchange in StackExchange: Divergences between Stack Overflow and its Culturally Diverse Participants", Proceedings of ACM Conference on Computer Supported Cooperative Work and Social Computing (CSCW), 2018.  (uses value sensitive analysis and interviews to show that StackOverflow’s design and rules make the platform inherently less engaging for people from collectivist cultures (e.g., for some people from China) 
* Katharina Reinecke and Krzysztof Gajos, "Quantifying Visual Preferences Around the World", Human Factors in Computing Systems (CHI), 2014. (quantitative analysis of website preferences showing that aesthetic appeal differs across countries, which suggests that some people will trust certain websites more than others) 
* August, Tal, Dallas Card, Gary Hsieh, Noah A. Smith, and Katharina Reinecke. "Explain like I am a Scientist: The Linguistic Barriers of Entry to r/science." In Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems, pp. 1-12. 2020. (shows that scientific jargon can be a barrier towards engaging with science news for newcomers in the community)
* Obermeyer, Z., Powers, B., Vogeli, C., & Mullainathan, S. (2019). Dissecting racial bias in an algorithm used to manage the health of populations. Science, 366(6464), 447-453. (shows racial bias in health algorithms that lead to Black patients being identified for extra care only half as often as White patients) 
* Metaxa-Kakavouli, Danaë, Kelly Wang, James A. Landay, and Jeff Hancock. "Gender-inclusive design: Sense of belonging and bias in web interfaces." In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems, pp. 1-6. 2018.
* Veinot, T. C., Mitchell, H., & Ancker, J. S. (2018). Good intentions are not enough: how informatics interventions can worsen inequality. Journal of the American Medical Informatics Association, 25(8), 1080-1088.

### Imagine: Imagine the end-point not as “fairness”, but as co-liberation

* The Digital Defense Playbook, which aims to change who gets to define problems around data collection, data privacy and data security---from elites to impacted communities. The digital defense playbook is a new method that uses community-based workshops for sharing stories about data. 
* Binns, Reuben, Max Van Kleek, Michael Veale, Ulrik Lyngs, Jun Zhao, and Nigel Shadbolt. "'It's Reducing a Human Being to a Percentage' Perceptions of Justice in Algorithmic Decisions." In Proceedings of the 2018 Chi conference on human factors in computing systems, pp. 1-14. 2018. Explores how we can and should explain decisions to users. 
* Bender, E. M., & Friedman, B. (2018). Data statements for natural language processing: Toward mitigating system bias and enabling better science. Transactions of the Association for Computational Linguistics, 6, 587-604.
* Gebru, T., Morgenstern, J., Vecchione, B., Vaughan, J. W., Wallach, H., Daumé III, H., & Crawford, K. (2018). Datasheets for datasets. arXiv preprint arXiv:1803.09010.
* Vorvoreanu, M., Zhang, L., Huang, Y. H., Hilderbrand, C., Steine-Hanson, Z., & Burnett, M. (2019, May). From gender biases to gender-inclusive design: An empirical investigation. In Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems (pp. 1-14).
What are metrics of success for evaluating co-liberated systems? 

### Teach: How might we engage and empower newcomers to the field of computer ethics, including practitioners and researchers?
* How can we teach specific topics in computer science and related fields to minority populations? 
Local Lotto project
* Moore, J. (2020, January). Towards a more representative politics in the ethics of computer science. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency (pp. 414-424).
* How can we teach researchers and practitioners about ethics and societal implications? Could we develop tools that could help them anticipate potential unintended consequences? (This paper provides a good overview of existing tools:  Shruthi Sai Chivukula, Ziqing Li, Anne C Pivonka, Jingning Chen, and Colin M Gray. 2021. Surveying the Landscape of Ethics-Focused Design Methods. arXiv preprint arXiv:2102.08909 (2021).) 
